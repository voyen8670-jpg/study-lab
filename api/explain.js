export default async function handler(req, res) {
  try {
    const { question } = req.body;

    if (!question) {
      return res.status(400).json({ answer: "‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi!" });
    }

    const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "llama3-8b-8192",
        messages: [
          {
            role: "system",
            content:
              "B·∫°n l√† tr·ª£ l√Ω AI trong ph√≤ng th√≠ nghi·ªám Study Lab, chuy√™n gi·∫£i th√≠ch th√≠ nghi·ªám L√Ω, H√≥a, Sinh m·ªôt c√°ch ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, th√¢n thi·ªán v·ªõi h·ªçc sinh."
          },
          {
            role: "user",
            content: question
          }
        ],
        max_tokens: 250,
        temperature: 0.7
      })
    });

    const data = await response.json();

    // üß† N·∫øu API tr·∫£ v·ªÅ l·ªói
    if (data.error) {
      console.error("Groq API Error:", data.error);
      return res.status(500).json({
        answer: "‚ö†Ô∏è M√°y ch·ªß AI ƒëang t·∫°m qu√° t·∫£i, vui l√≤ng th·ª≠ l·∫°i sau v√†i ph√∫t."
      });
    }

    const answer = data.choices?.[0]?.message?.content || "ü§ñ Xin l·ªói, m√¨nh ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n.";
    res.status(200).json({ answer });
  } catch (error) {
    console.error("Server Error:", error);
    res.status(500).json({
      answer: "‚ö†Ô∏è L·ªói m√°y ch·ªß ‚Äî kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi AI. Vui l√≤ng ki·ªÉm tra l·∫°i API key ho·∫∑c m·∫°ng."
    });
  }
}
